{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-0f6c7680cded>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mdsets\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torchvision'"
     ]
    }
   ],
   "source": [
    "#using Dataset class\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "rootDir = '/media/mohak/Free/sets'\n",
    "\n",
    "# class nuclei(Dataset):\n",
    "#     def __init__(self, rootDir = '/media/mohak/Free/sets/class0' , size=(250,250)):\n",
    "#         self.files = glob(rootDir)\n",
    "#         self.size = size\n",
    "        \n",
    "#     def __len__(self):\n",
    "#         #returns max no of images in dataset\n",
    "#         return len(self.files)\n",
    "        \n",
    "#     def __getitem__(self,idx):\n",
    "#         #returns an object based on idx\n",
    "#         img = np.asarray(Image.open(self.files[idx]).resize(self.size))\n",
    "#         label = self.files[idx].split('/')[-2]\n",
    "#         return img,label\n",
    "        \n",
    "#d = nuclei()\n",
    "#train_loader = torch.utils.data.DataLoader(d)\n",
    "\n",
    "TRANSFORM_IMG = transforms.Compose([\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install -c soumith torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullData = torchvision.datasets.ImageFolder(root=rootDir, transform=TRANSFORM_IMG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'full_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-0a06785d6b82>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.8\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_dataset\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'full_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "train_size = int(0.8 * len(fullData))\n",
    "test_size = len(fullData) - train_size\n",
    "train_data, test_data = torch.utils.data.random_split(full_dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = torch.utils.data.DataLoader(train_data, batch_size=5, shuffle=True,  num_workers=2)\n",
    "test_data_loader = torch.utils.data.DataLoader(test_data, batch_size=5, shuffle=False,  num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    #conv\n",
    "    #maxpool\n",
    "    #conv\n",
    "    #maxpool\n",
    "    #flatten\n",
    "    #feedforward\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=2)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.cnn2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.fcl = nn.Linear(32*64*64, 8)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.cnn1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.maxpool1(out)\n",
    "        out = self.cnn2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.maxpool2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fcl(out)\n",
    "        return out\n",
    "        \n",
    "model = CNN().cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter = 0, acc = 32, loss = 1.8739036321640015\n",
      "iter = 1, acc = 48, loss = 1.4064931869506836\n",
      "iter = 2, acc = 59, loss = 1.343585729598999\n",
      "iter = 3, acc = 57, loss = 1.4250153303146362\n",
      "iter = 4, acc = 52, loss = 1.3676478862762451\n",
      "iter = 5, acc = 63, loss = 1.0733404159545898\n",
      "iter = 6, acc = 83, loss = 0.9923189282417297\n",
      "iter = 7, acc = 72, loss = 0.25658315420150757\n",
      "iter = 8, acc = 76, loss = 1.0472021102905273\n",
      "iter = 9, acc = 78, loss = 1.8427234888076782\n",
      "iter = 10, acc = 90, loss = 0.38090139627456665\n"
     ]
    }
   ],
   "source": [
    "iter=0\n",
    "epochs = 11\n",
    "for epoc in range(epochs):\n",
    "    for i, (image, label) in enumerate(train_data_loader):\n",
    "        image = Variable(image.cuda())\n",
    "        label = Variable(label.cuda())\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(image)\n",
    "        loss = criterion(outputs, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        iter+=1\n",
    "        if iter%50==0:\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for images,lables in train_data_loader:\n",
    "                images = Variable(images).cuda()\n",
    "                outputs = model(images)\n",
    "                _,pred = torch.max(outputs.data,1)\n",
    "                total += lables.size(0)\n",
    "                correct += (pred.cpu()==lables.cpu()).sum()\n",
    "            accuracy = 100*correct/total\n",
    "            print('iter = {}, acc = {}, loss = {}'.format(epoc, accuracy, loss.item()))\n",
    "            \n",
    "#after 11 epochs, accuracy=90%, loss=0.3809"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the model\n",
    "torch.save(model.state_dict(),'/media/mohak/Free/NucleiClassifier.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 6\n",
      "1 6\n",
      "2 6\n",
      "3 6\n",
      "4 6\n",
      "5 6\n",
      "6 6\n",
      "7 7\n",
      "8 6\n",
      "9 6\n",
      "10 6\n",
      "11 6\n",
      "12 6\n",
      "13 6\n",
      "14 6\n",
      "15 6\n",
      "16 6\n",
      "17 6\n",
      "18 6\n",
      "19 6\n",
      "20 6\n",
      "21 6\n",
      "22 6\n",
      "23 6\n",
      "24 6\n",
      "25 6\n",
      "26 6\n",
      "27 6\n",
      "28 6\n",
      "29 6\n",
      "30 6\n",
      "31 6\n",
      "32 6\n",
      "33 6\n",
      "34 6\n",
      "35 6\n",
      "36 6\n",
      "37 6\n",
      "38 6\n",
      "39 6\n",
      "40 6\n",
      "41 6\n",
      "42 6\n",
      "43 6\n",
      "44 7\n",
      "45 6\n",
      "46 6\n",
      "47 6\n",
      "48 6\n",
      "49 6\n",
      "50 6\n",
      "51 6\n",
      "52 6\n",
      "53 6\n",
      "54 6\n",
      "55 6\n",
      "56 6\n",
      "57 6\n",
      "58 6\n",
      "59 6\n",
      "60 6\n",
      "61 6\n",
      "62 6\n",
      "63 6\n",
      "64 6\n"
     ]
    }
   ],
   "source": [
    "#tesing the model\n",
    "\n",
    "TRANSFORM_IMG = transforms.Compose([\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.ToTensor()\n",
    "    ])\n",
    "rootPred='/media/mohak/Free/Nuclei/stage_1_test(65img)'\n",
    "pred_data = torchvision.datasets.ImageFolder(root=rootPred, transform=TRANSFORM_IMG)\n",
    "test_data_loader = torch.utils.data.DataLoader(pred_data, batch_size=1, shuffle=False,  num_workers=2)\n",
    "for i,(image,label) in enumerate(test_data_loader):\n",
    "    image = Variable(image.cuda())\n",
    "    output = model(image)\n",
    "    pred = prediction = int(torch.max(output.cpu().data, 1)[1].numpy())\n",
    "    print(i,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
